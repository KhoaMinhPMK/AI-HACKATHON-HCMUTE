/**
 * Groq API Client for Reasoning Models
 * Using gpt-oss-120b for advanced thinking
 */

class GroqClient {
    constructor(apiKey) {
        this.apiKey = apiKey;
        this.baseURL = 'https://api.groq.com/openai/v1/chat/completions';
        this.model = 'openai/gpt-oss-120b'; // Advanced reasoning model
    }

    /**
     * Send chat completion request with reasoning
     * @param {Array} messages - Array of {role, content}
     * @param {Object} options - Additional options
     * @returns {Promise<Object>} Response with content and reasoning
     */
    async chat(messages, options = {}) {
        const payload = {
            model: this.model,
            messages: messages,
            temperature: options.temperature || 0.6,
            max_completion_tokens: options.max_tokens || 2048,
            top_p: options.top_p || 0.95,
            stream: options.stream || false,
            reasoning_effort: options.reasoning_effort || 'high', // low, medium, high
            include_reasoning: options.include_reasoning !== false // default true
        };

        try {
            const response = await fetch(this.baseURL, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                const error = await response.json();
                throw new Error(`Groq API error: ${response.status} ${JSON.stringify(error)}`);
            }

            const data = await response.json();
            
            // Extract content and reasoning
            const choice = data.choices[0];
            const result = {
                content: choice.message.content,
                reasoning: choice.message.reasoning || null,
                model: data.model,
                usage: data.usage,
                finish_reason: choice.finish_reason
            };

            console.log('‚úÖ Groq API response:', {
                model: result.model,
                tokens: result.usage,
                reasoning_length: result.reasoning?.length || 0
            });

            return result;

        } catch (error) {
            console.error('‚ùå Groq API error:', error);
            throw error;
        }
    }

    /**
     * Stream chat completion (for real-time responses)
     * @param {Array} messages 
     * @param {Function} onChunk - Callback for each chunk
     * @param {Object} options 
     */
    async chatStream(messages, onChunk, options = {}) {
        const payload = {
            model: this.model,
            messages: messages,
            temperature: options.temperature || 0.6,
            max_completion_tokens: options.max_tokens || 2048,
            top_p: 0.95,
            stream: true,
            reasoning_effort: options.reasoning_effort || 'high',
            include_reasoning: options.include_reasoning !== false
        };

        try {
            const response = await fetch(this.baseURL, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                throw new Error(`Groq API error: ${response.status}`);
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let buffer = '';

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                buffer += decoder.decode(value, { stream: true });
                const lines = buffer.split('\n');
                buffer = lines.pop() || '';

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6);
                        if (data === '[DONE]') continue;

                        try {
                            const parsed = JSON.parse(data);
                            const delta = parsed.choices[0]?.delta;
                            
                            if (delta?.content) {
                                onChunk({
                                    type: 'content',
                                    text: delta.content
                                });
                            }

                            if (delta?.reasoning) {
                                onChunk({
                                    type: 'reasoning',
                                    text: delta.reasoning
                                });
                            }
                        } catch (e) {
                            console.warn('Failed to parse SSE chunk:', e);
                        }
                    }
                }
            }

            onChunk({ type: 'done' });

        } catch (error) {
            console.error('‚ùå Groq stream error:', error);
            throw error;
        }
    }

    /**
     * Generate research advice with deep reasoning
     * @param {string} topic - Research topic
     * @param {string} context - Additional context
     * @returns {Promise<Object>}
     */
    async getResearchAdvice(topic, context = '') {
        const messages = [
            {
                role: 'user',
                content: `B·∫°n l√† chuy√™n gia t∆∞ v·∫•n nghi√™n c·ª©u khoa h·ªçc. H√£y ph√¢n t√≠ch v√† ƒë·ªÅ xu·∫•t h∆∞·ªõng nghi√™n c·ª©u cho ƒë·ªÅ t√†i sau:

**ƒê·ªÅ t√†i:** ${topic}

${context ? `**Th√¥ng tin th√™m:** ${context}` : ''}

H√£y ƒë∆∞a ra:
1. üìä Ph√¢n t√≠ch t·ªïng quan v·ªÅ ch·ªß ƒë·ªÅ (xu h∆∞·ªõng, th√°ch th·ª©c, c∆° h·ªôi)
2. üéØ 3-5 h∆∞·ªõng nghi√™n c·ª©u c·ª• th·ªÉ c√≥ th·ªÉ th·ª±c hi·ªán
3. üìö C√°c ph∆∞∆°ng ph√°p nghi√™n c·ª©u ph√π h·ª£p
4. ‚ö†Ô∏è Nh·ªØng l∆∞u √Ω, kh√≥ khƒÉn ti·ªÅm ·∫©n
5. üí° G·ª£i √Ω t√†i li·ªáu, c√¥ng c·ª•, dataset

Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, r√µ r√†ng, c√≥ c·∫•u tr√∫c.`
            }
        ];

        return await this.chat(messages, {
            temperature: 0.7,
            max_tokens: 3000,
            reasoning_effort: 'high'
        });
    }

    /**
     * Analyze papers and generate insights
     * @param {string} query - Search query
     * @param {Array} papers - List of papers
     * @returns {Promise<Object>}
     */
    async analyzePapers(query, papers) {
        const paperSummaries = papers.slice(0, 5).map((p, i) => 
            `${i+1}. "${p.title}" (${p.year}) - ${p.citationCount} citations\n   ${p.abstract.slice(0, 200)}...`
        ).join('\n\n');

        const messages = [
            {
                role: 'user',
                content: `Ph√¢n t√≠ch c√°c b√†i b√°o khoa h·ªçc li√™n quan ƒë·∫øn: "${query}"

**Top 5 b√†i b√°o:**
${paperSummaries}

H√£y ƒë∆∞a ra:
1. üîç T·ªïng quan xu h∆∞·ªõng nghi√™n c·ª©u
2. üìà Nh·ªØng ti·∫øn b·ªô ch√≠nh trong lƒ©nh v·ª±c
3. üéØ Gap c√≤n thi·∫øu, h∆∞·ªõng nghi√™n c·ª©u ti·ªÅm nƒÉng
4. üí° G·ª£i √Ω cho ng∆∞·ªùi mu·ªën nghi√™n c·ª©u ch·ªß ƒë·ªÅ n√†y

Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch, b·∫±ng ti·∫øng Vi·ªát.`
            }
        ];

        return await this.chat(messages, {
            temperature: 0.6,
            max_tokens: 1500,
            reasoning_effort: 'medium'
        });
    }
}

// Create singleton instance with API key from config
// Make sure to load config.js before this file
const groqClient = typeof API_CONFIG !== 'undefined' && API_CONFIG.GROQ_API_KEY 
    ? new GroqClient(API_CONFIG.GROQ_API_KEY)
    : null;

if (!groqClient) {
    console.warn('‚ö†Ô∏è Groq API key not configured. Please set API_CONFIG.GROQ_API_KEY in config.js');
}

console.log('ü§ñ Groq Client loaded with gpt-oss-120b (thinking model)');

// Export for use in other scripts
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { GroqClient, groqClient };
}
